# -*- coding: utf-8 -*-
"""lvadsusr139_class_Anbu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10RN08Ibqp3PEf9_eOWCIzvcfwunI2bmf

Importing Libraries
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler,LabelEncoder,OrdinalEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

"""Reading Data"""

data=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/penguins_classification.csv')

"""Describe"""

data.describe()

"""Info"""

data.info()

data.columns

"""Missing Values"""

data.isna().sum()#no missing values

"""Duplicates"""

data.duplicated().sum()# no duplicates

"""Correlation Matrix"""

numerical_col= data.select_dtypes(include=['int','float'])
correl = numerical_col.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correl, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()
print()

"""Outliers box plot and removal"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=data)
plt.title("Boxplot of Variables")
plt.xticks(rotation=45)
plt.show()
print()# outliers on the data set

numerical_columns=data.select_dtypes(include=['int','float'])

for col in numerical_columns.columns:
    ninety_fifth_percentile = data[col].quantile(0.95)
    data[col] = np.where(numerical_columns[col] > ninety_fifth_percentile, ninety_fifth_percentile, numerical_columns[col])

plt.figure(figsize=(12, 6))
sns.boxplot(data=data)
plt.title("Boxplot of Variables after Handling Outliers")
plt.xticks(rotation=45)
plt.show()

data.columns

X = data.drop('species', axis=1)
y = data['species']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# lable encoders are for target datas
X_train_encoded = pd.get_dummies(X_train)
X_test_encoded = pd.get_dummies(X_test)

#label encoding is for targets
l= LabelEncoder()
Y_train_encoded =l.fit_transform(y_train)
Y_test_encoded = l.transform(y_test)

X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='outer', axis=1, fill_value=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_encoded)
X_test_scaled = scaler.transform(X_test_encoded)

X_train_scaled=pd.DataFrame(X_train_scaled)
X_train_scaled.isna().sum()

X_test_scaled=pd.DataFrame(X_test_scaled)
X_test_scaled.isna().sum()

X_train_scaled=X_train_scaled.fillna(X_train_scaled.mean(),inplace=False)

X_test_scaled=X_test_scaled.fillna(X_test_scaled.mean(),inplace=False)

model = LogisticRegression()
model.fit(X_train_scaled, y_train)

y_pred = model.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print()
print("Accuracy:", accuracy)
print()
print("Classification Report:\n", report)
print()